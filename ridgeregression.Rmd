---
title: "ridge regression"
author: "Daniel Gao, Aarnav Putta"
date: "2024-11-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Front Matter
```{r}
#Load Packages
library(tidyverse)
library(glmnet) #To perform LASSO and Ridge
```


### Data
```{r}
test = read.csv("./test_timeseries.csv/test_timeseries.csv")
train = read.csv("./train_timeseries.csv/train_timeseries.csv") 
val = read.csv("./validation_timeseries.csv/validation_timeseries.csv") 
soil = read.csv("./soil_data.csv")
```

```{r}
#Combine test, train, val - will be used later in the code block
Drought <-
  test %>%
  bind_rows(train) %>%
  bind_rows(val)

DroughtED <-
  Drought %>%
  filter(score != 0)

cat("Results from removing the null values\n", 
    "Before:", nrow(Drought), "\n",
    "After:", nrow(DroughtED),"\n",
    "Total Removed:", nrow(Drought) - nrow(DroughtED),"\n",
    "Percentage Removed:",1-nrow(DroughtED)/nrow(Drought) )
```

### Splitting Data 
```{r}
#### Part a - Preparing the data for glmnet
#Create input matrix and response vector
Xmat <- model.matrix(score ~ PRECTOT+PS+QV2M+T2M+T2MDEW+T2MWET+T2M_MAX+T2M_MIN+T2M_RANGE+TS+WS10M+WS10M_MAX+WS10M_MIN+WS10M_RANGE+WS50M+WS50M_MAX+WS50M_MIN+WS50M_RANGE, data = DroughtED)[, -1]
yvec <- DroughtED$score

#Perform 80/20 training/validation split using seed of 1
set.seed(1)
trainInd <- sample(1:nrow(DroughtED), floor(0.8*nrow(DroughtED)))
set.seed(NULL)

#Split Xmat and yvec separately
XmatTrain <- Xmat[trainInd, ]
XmatVal <- Xmat[-trainInd, ]
yvecTrain <- yvec[trainInd]
yvecVal <- yvec[-trainInd]
```

#### Initialize Ridge Model
```{r}
#Fit the Ridge model (let R choice lambda sequence)
ridgeModel <- glmnet(x = XmatTrain, y = yvecTrain,
                     family = "gaussian",
                     alpha = 0, 
                     lambda = NULL,
                     standardize = TRUE)

#Create a plot of the coefficient paths
plot(ridgeModel, xvar = "lambda", label = TRUE)
```

#### Pick Optimal Value of Lambda for Ridge
```{r}
#Use 10-fold CV to pick lambda for Ridge
set.seed(123)
ridgeCV <- cv.glmnet(x = XmatTrain, y = yvecTrain,
                    family = "gaussian",
                    alpha = 0, 
                    lambda = NULL,
                    standardize = TRUE,
                    nfolds = 10)
set.seed(NULL)

#Show the Ridge CV results
plot(ridgeCV)
```

#### Train/Predict Model
```{r}
#Ridge 122.15
ridgeYhat <- predict(ridgeCV, 
                     s=ridgeCV$lambda.min,
                     newx = XmatVal)

ridgeMSE <- mean((yvecVal - ridgeYhat)^2)
ridgeRMSE <- sqrt(ridgeMSE)
ridgeRMSE

#Least Squares (train and validation are not the same as we used in cv.glmnet) 103.49
train <- DroughtED[trainInd, ]
validation <- DroughtED[-trainInd, ]

model1 <- lm(score ~ PRECTOT+PS+QV2M+T2M+T2MDEW+T2MWET+T2M_MAX+T2M_MIN+T2M_RANGE+TS+WS10M+WS10M_MAX+WS10M_MIN+WS10M_RANGE+WS50M+WS50M_MAX+WS50M_MIN+WS50M_RANGE, data = train)
yhat <- predict(model1, newdata = validation)
MSEval1 <- mean((validation$score - yhat)^2)

#Calculate RMSE
RMSEval1 <- sqrt(MSEval1)
RMSEval1 
```





