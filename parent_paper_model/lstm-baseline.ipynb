{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1992077,"sourceType":"datasetVersion","datasetId":1108326}],"dockerImageVersionId":30056,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"> ## US Drought & Meteorological Data Starter Notebook\nThis notebook will walk you trough loading the data and create a Dummy Classifier, showing a range of F1 scores that correspond to random predictions if given theclass priors.","metadata":{}},{"cell_type":"markdown","source":"## Loading & Visualizing the Data\nIn this section, we load the training and validation data into numpy arrays and visualize the drought classes and meteorological attributes.","metadata":{}},{"cell_type":"markdown","source":"We load the json files for training, validation and testing into the ``files`` dictionary.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport os\nfrom tqdm.auto import tqdm\nfrom datetime import datetime\nfrom scipy.interpolate import interp1d\nfrom sklearn.preprocessing import RobustScaler\n\nfiles = {}\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if 'train' in filename:\n            files['train'] = os.path.join(dirname, filename)\n        if 'valid' in filename:\n            files['valid'] = os.path.join(dirname, filename)\n        if 'test' in filename:\n            files['test'] = os.path.join(dirname, filename)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-11-11T02:57:42.144603Z","iopub.execute_input":"2024-11-11T02:57:42.145045Z","iopub.status.idle":"2024-11-11T02:57:42.491834Z","shell.execute_reply.started":"2024-11-11T02:57:42.144953Z","shell.execute_reply":"2024-11-11T02:57:42.490919Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"The following classes exist, ranging from no drought (``None``), to extreme drought (``D4``).\nThis could be treated as a regression, ordinal or classification problem, but for now we will treat it as 5 distinct classes.","metadata":{}},{"cell_type":"code","source":"class2id = {\n    'None': 0,\n    'D0': 1,\n    'D1': 2,\n    'D2': 3,\n    'D3': 4,\n    'D4': 5,\n}\nid2class = {v: k for k, v in class2id.items()}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-11T02:57:42.493849Z","iopub.execute_input":"2024-11-11T02:57:42.494209Z","iopub.status.idle":"2024-11-11T02:57:42.499969Z","shell.execute_reply.started":"2024-11-11T02:57:42.494165Z","shell.execute_reply":"2024-11-11T02:57:42.499003Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"Now we'll define a helper method to load the datasets. This just walks through the json and discards the few samples that are corrupted.","metadata":{}},{"cell_type":"code","source":"dfs = {\n    k: pd.read_csv(files[k]).set_index(['fips', 'date'])\n    for k in files.keys()\n}","metadata":{"execution":{"iopub.status.busy":"2024-11-11T02:57:42.501249Z","iopub.execute_input":"2024-11-11T02:57:42.501551Z","iopub.status.idle":"2024-11-11T02:58:41.033209Z","shell.execute_reply.started":"2024-11-11T02:57:42.501523Z","shell.execute_reply":"2024-11-11T02:58:41.032248Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"We also add a helper function to interpolate the drought values.","metadata":{}},{"cell_type":"code","source":"def interpolate_nans(padata, pkind='linear'):\n    \"\"\"\n    see: https://stackoverflow.com/a/53050216/2167159\n    \"\"\"\n    aindexes = np.arange(padata.shape[0])\n    agood_indexes, = np.where(np.isfinite(padata))\n    f = interp1d(agood_indexes\n               , padata[agood_indexes]\n               , bounds_error=False\n               , copy=False\n               , fill_value=\"extrapolate\"\n               , kind=pkind)\n    return f(aindexes)","metadata":{"execution":{"iopub.status.busy":"2024-11-11T02:58:41.034545Z","iopub.execute_input":"2024-11-11T02:58:41.034874Z","iopub.status.idle":"2024-11-11T02:58:41.040225Z","shell.execute_reply.started":"2024-11-11T02:58:41.034844Z","shell.execute_reply":"2024-11-11T02:58:41.039467Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"We encode the day of year using sin/cos and add the data loading function `loadXY`.","metadata":{}},{"cell_type":"code","source":"def date_encode(date):\n    if isinstance(date, str):\n        date = datetime.strptime(date, \"%Y-%m-%d\")\n    return (\n        np.sin(2 * np.pi * date.timetuple().tm_yday / 366),\n        np.cos(2 * np.pi * date.timetuple().tm_yday / 366),\n    )\n\ndef loadXY(\n    df,\n    random_state=42, # keep this at 42\n    window_size=180, # how many days in the past (default/competition: 180)\n    target_size=6, # how many weeks into the future (default/competition: 6)\n    fuse_past=True, # add the past drought observations? (default: True)\n    return_fips=False, # return the county identifier (do not use for predictions)\n    encode_season=True, # encode the season using the function above (default: True) \n    use_prev_year=False, # add observations from 1 year prior?\n):\n    df = dfs[df]\n    soil_df = pd.read_csv(\"/kaggle/input/soil_data.csv\")\n    time_data_cols = sorted(\n        [c for c in df.columns if c not in [\"fips\", \"date\", \"score\"]]\n    )\n    static_data_cols = sorted(\n        [c for c in soil_df.columns if c not in [\"soil\", \"lat\", \"lon\"]]\n    )\n    count = 0\n    score_df = df.dropna(subset=[\"score\"])\n    X_static = np.empty((len(df) // window_size, len(static_data_cols)))\n    X_fips_date = []\n    add_dim = 0\n    if use_prev_year:\n        add_dim += len(time_data_cols)\n    if fuse_past:\n        add_dim += 1\n        if use_prev_year:\n            add_dim += 1\n    if encode_season:\n        add_dim += 2\n    X_time = np.empty(\n        (len(df) // window_size, window_size, len(time_data_cols) + add_dim)\n    )\n    y_past = np.empty((len(df) // window_size, window_size))\n    y_target = np.empty((len(df) // window_size, target_size))\n    if random_state is not None:\n        np.random.seed(random_state)\n    for fips in tqdm(score_df.index.get_level_values(0).unique()):\n        if random_state is not None:\n            start_i = np.random.randint(1, window_size)\n        else:\n            start_i = 1\n        fips_df = df[(df.index.get_level_values(0) == fips)]\n        X = fips_df[time_data_cols].values\n        y = fips_df[\"score\"].values\n        X_s = soil_df[soil_df[\"fips\"] == fips][static_data_cols].values[0]\n        for i in range(start_i, len(y) - (window_size + target_size * 7), window_size):\n            X_fips_date.append((fips, fips_df.index[i : i + window_size][-1]))\n            X_time[count, :, : len(time_data_cols)] = X[i : i + window_size]\n            if use_prev_year:\n                if i < 365 or len(X[i - 365 : i + window_size - 365]) < window_size:\n                    continue\n                X_time[count, :, -len(time_data_cols) :] = X[\n                    i - 365 : i + window_size - 365\n                ]\n            if not fuse_past:\n                y_past[count] = interpolate_nans(y[i : i + window_size])\n            else:\n                X_time[count, :, len(time_data_cols)] = interpolate_nans(\n                    y[i : i + window_size]\n                )\n            if encode_season:\n                enc_dates = [\n                    date_encode(d) for f, d in fips_df.index[i : i + window_size].values\n                ]\n                d_sin, d_cos = [s for s, c in enc_dates], [c for s, c in enc_dates]\n                X_time[count, :, len(time_data_cols) + (add_dim - 2)] = d_sin\n                X_time[count, :, len(time_data_cols) + (add_dim - 2) + 1] = d_cos\n            temp_y = y[i + window_size : i + window_size + target_size * 7]\n            y_target[count] = np.array(temp_y[~np.isnan(temp_y)][:target_size])\n            X_static[count] = X_s\n            count += 1\n    print(f\"loaded {count} samples\")\n    results = [X_static[:count], X_time[:count], y_target[:count]]\n    if not fuse_past:\n        results.append(y_past[:count])\n    if return_fips:\n        results.append(X_fips_date)\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-11-11T02:58:41.043249Z","iopub.execute_input":"2024-11-11T02:58:41.043566Z","iopub.status.idle":"2024-11-11T02:58:41.066649Z","shell.execute_reply.started":"2024-11-11T02:58:41.043539Z","shell.execute_reply":"2024-11-11T02:58:41.065774Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Now we add a helper to normalise the data.","metadata":{}},{"cell_type":"code","source":"scaler_dict = {}\nscaler_dict_static = {}\nscaler_dict_past = {}\n\n\ndef normalize(X_static, X_time, y_past=None, fit=False):\n    for index in tqdm(range(X_time.shape[-1])):\n        if fit:\n            scaler_dict[index] = RobustScaler().fit(X_time[:, :, index].reshape(-1, 1))\n        X_time[:, :, index] = (\n            scaler_dict[index]\n            .transform(X_time[:, :, index].reshape(-1, 1))\n            .reshape(-1, X_time.shape[-2])\n        )\n    for index in tqdm(range(X_static.shape[-1])):\n        if fit:\n            scaler_dict_static[index] = RobustScaler().fit(\n                X_static[:, index].reshape(-1, 1)\n            )\n        X_static[:, index] = (\n            scaler_dict_static[index]\n            .transform(X_static[:, index].reshape(-1, 1))\n            .reshape(1, -1)\n        )\n    index = 0\n    if y_past is not None:\n        if fit:\n            scaler_dict_past[index] = RobustScaler().fit(y_past.reshape(-1, 1))\n        y_past[:, :] = (\n            scaler_dict_past[index]\n            .transform(y_past.reshape(-1, 1))\n            .reshape(-1, y_past.shape[-1])\n        )\n        return X_static, X_time, y_past\n    return X_static, X_time","metadata":{"execution":{"iopub.status.busy":"2024-11-11T02:58:41.068420Z","iopub.execute_input":"2024-11-11T02:58:41.068791Z","iopub.status.idle":"2024-11-11T02:58:41.081246Z","shell.execute_reply.started":"2024-11-11T02:58:41.068757Z","shell.execute_reply":"2024-11-11T02:58:41.080253Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"X_static_train, X_time_train, y_target_train = loadXY(\"train\")\nprint(\"train shape\", X_time_train.shape)\nX_static_valid, X_time_valid, y_target_valid, valid_fips = loadXY(\"valid\", return_fips=True)\nprint(\"validation shape\", X_time_valid.shape)\nX_static_train, X_time_train = normalize(X_static_train, X_time_train, fit=True)\nX_static_valid, X_time_valid = normalize(X_static_valid, X_time_valid)","metadata":{"execution":{"iopub.status.busy":"2024-11-11T02:58:41.082361Z","iopub.execute_input":"2024-11-11T02:58:41.082673Z","iopub.status.idle":"2024-11-11T03:12:00.127501Z","shell.execute_reply.started":"2024-11-11T02:58:41.082644Z","shell.execute_reply":"2024-11-11T03:12:00.126653Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3108 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41f5cc49caff400e8912d93d9b379122"}},"metadata":{}},{"name":"stdout","text":"loaded 103390 samples\ntrain shape (103390, 180, 21)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3108 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c392c6bc4faf4581b545874a66af8870"}},"metadata":{}},{"name":"stdout","text":"loaded 8748 samples\nvalidation shape (8748, 180, 21)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/21 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8d3f73007b0476393d69ec1f4834023"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5a3523de6fe40ec976a3ec387793909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/21 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19d4e69613334b80bc8338f00b78e118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"612c1df0c5224d988bff1a0a386b0845"}},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"Below we use PyTorch to load the data.","metadata":{}},{"cell_type":"code","source":"batch_size = 128\noutput_weeks = 6\nuse_static = True\nhidden_dim = 512\nn_layers = 2\nffnn_layers = 2\ndropout = 0.1\none_cycle = True\nlr = 7e-5\nepochs = 10\nclip = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:12:00.128690Z","iopub.execute_input":"2024-11-11T03:12:00.128974Z","iopub.status.idle":"2024-11-11T03:12:00.133951Z","shell.execute_reply.started":"2024-11-11T03:12:00.128946Z","shell.execute_reply":"2024-11-11T03:12:00.133008Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\ntrain_data = TensorDataset(\n    torch.tensor(X_time_train),\n    torch.tensor(X_static_train),\n    torch.tensor(y_target_train[:, :output_weeks]),\n)\ntrain_loader = DataLoader(\n    train_data, shuffle=True, batch_size=batch_size, drop_last=False\n)\nvalid_data = TensorDataset(\n    torch.tensor(X_time_valid),\n    torch.tensor(X_static_valid),\n    torch.tensor(y_target_valid[:, :output_weeks]),\n)\nvalid_loader = DataLoader(\n    valid_data, shuffle=False, batch_size=batch_size, drop_last=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:12:00.135203Z","iopub.execute_input":"2024-11-11T03:12:00.135631Z","iopub.status.idle":"2024-11-11T03:12:01.542627Z","shell.execute_reply.started":"2024-11-11T03:12:00.135568Z","shell.execute_reply":"2024-11-11T03:12:01.541800Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom sklearn.metrics import f1_score, mean_absolute_error\n\nclass DroughtNetLSTM(nn.Module):\n    def __init__(\n        self,\n        output_size,\n        num_input_features,\n        hidden_dim,\n        n_layers,\n        ffnn_layers,\n        drop_prob,\n        static_dim=0,\n    ):\n        super(DroughtNetLSTM, self).__init__()\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n\n        self.lstm = nn.LSTM(\n            num_input_features,\n            hidden_dim,\n            n_layers,\n            dropout=drop_prob,\n            batch_first=True,\n        )\n        self.dropout = nn.Dropout(drop_prob)\n        self.fflayers = []\n        for i in range(ffnn_layers - 1):\n            if i == 0:\n                self.fflayers.append(nn.Linear(hidden_dim + static_dim, hidden_dim))\n            else:\n                self.fflayers.append(nn.Linear(hidden_dim, hidden_dim))\n        self.fflayers = nn.ModuleList(self.fflayers)\n        self.final = nn.Linear(hidden_dim, output_size)\n\n    def forward(self, x, hidden, static=None):\n        batch_size = x.size(0)\n        x = x.to(dtype=torch.float32)\n        if static is not None:\n            static = static.to(dtype=torch.float32)\n        lstm_out, hidden = self.lstm(x, hidden)\n        lstm_out = lstm_out[:, -1, :]\n\n        out = self.dropout(lstm_out)\n        for i in range(len(self.fflayers)):\n            if i == 0 and static is not None:\n                out = self.fflayers[i](torch.cat((out, static), 1))\n            else:\n                out = self.fflayers[i](out)\n        out = self.final(out)\n\n        out = out.view(batch_size, -1)\n        return out, hidden\n\n    def init_hidden(self, batch_size):\n        weight = next(self.parameters()).data\n        hidden = (\n            weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n            weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n        )\n        return hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:12:01.544084Z","iopub.execute_input":"2024-11-11T03:12:01.544445Z","iopub.status.idle":"2024-11-11T03:12:01.570495Z","shell.execute_reply.started":"2024-11-11T03:12:01.544406Z","shell.execute_reply":"2024-11-11T03:12:01.569654Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"is_cuda = torch.cuda.is_available()\nif is_cuda:\n    device = torch.device(\"cuda\")\n    print(\"using GPU\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"using CPU\")\nstatic_dim = 0\nif use_static:\n    static_dim = X_static_train.shape[-1]\nmodel = DroughtNetLSTM(\n    output_weeks,\n    X_time_train.shape[-1],\n    hidden_dim,\n    n_layers,\n    ffnn_layers,\n    dropout,\n    static_dim,\n)\nmodel.to(device)\nloss_function = nn.MSELoss()\nif one_cycle:\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer, max_lr=lr, steps_per_epoch=len(train_loader), epochs=epochs\n    )\nelse:\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\ncounter = 0\nvalid_loss_min = np.Inf\ntorch.manual_seed(42)\nnp.random.seed(42)\nfor i in range(epochs):\n    h = model.init_hidden(batch_size)\n\n    for k, (inputs, static, labels) in tqdm(\n        enumerate(train_loader),\n        desc=f\"epoch {i+1}/{epochs}\",\n        total=len(train_loader),\n    ):\n        model.train()\n        counter += 1\n        if len(inputs) < batch_size:\n            h = model.init_hidden(len(inputs))\n        h = tuple([e.data for e in h])\n        inputs, labels, static = (\n            inputs.to(device),\n            labels.to(device),\n            static.to(device),\n        )\n        model.zero_grad()\n        if use_static:\n            output, h = model(inputs, h, static)\n        else:\n            output, h = model(inputs, h)\n        loss = loss_function(output, labels.float())\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        if one_cycle:\n            scheduler.step()\n\n        with torch.no_grad():\n            if k == len(train_loader) - 1 or k == (len(train_loader) - 1) // 2:\n                val_h = model.init_hidden(batch_size)\n                val_losses = []\n                model.eval()\n                labels = []\n                preds = []\n                raw_labels = []\n                raw_preds = []\n                for inp, stat, lab in valid_loader:\n                    if len(inp) < batch_size:\n                        val_h = model.init_hidden(len(inp))\n                    val_h = tuple([each.data for each in val_h])\n                    inp, lab, stat = inp.to(device), lab.to(device), stat.to(device)\n                    if use_static:\n                        out, val_h = model(inp, val_h, stat)\n                    else:\n                        out, val_h = model(inp, val_h)\n                    val_loss = loss_function(out, lab.float())\n                    val_losses.append(val_loss.item())\n                    for labs in lab:\n                        labels.append([int(l.round()) for l in labs])\n                        raw_labels.append([float(l) for l in labs])\n                    for pred in out:\n                        preds.append([int(p.round()) for p in pred])\n                        raw_preds.append([float(p) for p in pred])\n                # log data\n                labels = np.array(labels)\n                preds = np.clip(np.array(preds), 0, 5)\n                raw_preds = np.array(raw_preds)\n                raw_labels = np.array(raw_labels)\n                for i in range(output_weeks):\n                    log_dict = {\n                        \"loss\": float(loss),\n                        \"epoch\": counter / len(train_loader),\n                        \"step\": counter,\n                        \"lr\": optimizer.param_groups[0][\"lr\"],\n                        \"week\": i + 1,\n                    }\n                    # w = f'week_{i+1}_'\n                    w = \"\"\n                    log_dict[f\"{w}validation_loss\"] = np.mean(val_losses)\n                    log_dict[f\"{w}macro_f1\"] = f1_score(\n                        labels[:, i], preds[:, i], average=\"macro\"\n                    )\n                    log_dict[f\"{w}micro_f1\"] = f1_score(\n                        labels[:, i], preds[:, i], average=\"micro\"\n                    )\n                    log_dict[f\"{w}mae\"] = mean_absolute_error(\n                        raw_labels[:, i], raw_preds[:, i]\n                    )\n                    print(log_dict)\n                    for j, f1 in enumerate(\n                        f1_score(labels[:, i], preds[:, i], average=None)\n                    ):\n                        log_dict[f\"{w}{id2class[j]}_f1\"] = f1\n                    model.train()\n                if np.mean(val_losses) <= valid_loss_min:\n                    torch.save(model.state_dict(), \"./state_dict.pt\")\n                    print(\n                        \"Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...\".format(\n                            valid_loss_min, np.mean(val_losses)\n                        )\n                    )\n                    valid_loss_min = np.mean(val_losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:12:01.571682Z","iopub.execute_input":"2024-11-11T03:12:01.571937Z","iopub.status.idle":"2024-11-11T03:28:31.104116Z","shell.execute_reply.started":"2024-11-11T03:12:01.571912Z","shell.execute_reply":"2024-11-11T03:28:31.103277Z"}},"outputs":[{"name":"stdout","text":"using GPU\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 1/10:   0%|          | 0/808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d25339ac2f64a76a2ec0178470021ab"}},"metadata":{}},{"name":"stdout","text":"{'loss': 0.43339237570762634, 'epoch': 0.5, 'step': 404, 'lr': 7.305177512317032e-06, 'week': 1, 'validation_loss': 0.44861858845620917, 'macro_f1': 0.37847321789748456, 'micro_f1': 0.5899634202103338, 'mae': 0.47917601044422276}\n{'loss': 0.43339237570762634, 'epoch': 0.5, 'step': 404, 'lr': 7.305177512317032e-06, 'week': 2, 'validation_loss': 0.44861858845620917, 'macro_f1': 0.3599006358213352, 'micro_f1': 0.5674439871970736, 'mae': 0.5164739678778596}\n{'loss': 0.43339237570762634, 'epoch': 0.5, 'step': 404, 'lr': 7.305177512317032e-06, 'week': 3, 'validation_loss': 0.44861858845620917, 'macro_f1': 0.3367263428687836, 'micro_f1': 0.565843621399177, 'mae': 0.53627459259495}\n{'loss': 0.43339237570762634, 'epoch': 0.5, 'step': 404, 'lr': 7.305177512317032e-06, 'week': 4, 'validation_loss': 0.44861858845620917, 'macro_f1': 0.28867376077432466, 'micro_f1': 0.5370370370370371, 'mae': 0.5742118244287377}\n{'loss': 0.43339237570762634, 'epoch': 0.5, 'step': 404, 'lr': 7.305177512317032e-06, 'week': 5, 'validation_loss': 0.44861858845620917, 'macro_f1': 0.32002490413911916, 'micro_f1': 0.5832190214906264, 'mae': 0.5541380809404044}\n{'loss': 0.43339237570762634, 'epoch': 0.5, 'step': 404, 'lr': 7.305177512317032e-06, 'week': 6, 'validation_loss': 0.44861858845620917, 'macro_f1': 0.27263173125829465, 'micro_f1': 0.5470964791952446, 'mae': 0.5902960732760096}\nValidation loss decreased (inf --> 0.448619).  Saving model ...\n{'loss': 0.22113360464572906, 'epoch': 1.0, 'step': 808, 'lr': 1.9612577643465342e-05, 'week': 1, 'validation_loss': 0.2404813739484635, 'macro_f1': 0.7573419333272254, 'micro_f1': 0.8699131229995427, 'mae': 0.21752601509732122}\n{'loss': 0.22113360464572906, 'epoch': 1.0, 'step': 808, 'lr': 1.9612577643465342e-05, 'week': 2, 'validation_loss': 0.2404813739484635, 'macro_f1': 0.6663810800188281, 'micro_f1': 0.8204160951074532, 'mae': 0.2651899757815476}\n{'loss': 0.22113360464572906, 'epoch': 1.0, 'step': 808, 'lr': 1.9612577643465342e-05, 'week': 3, 'validation_loss': 0.2404813739484635, 'macro_f1': 0.6245206153335794, 'micro_f1': 0.7804069501600366, 'mae': 0.31119128075855745}\n{'loss': 0.22113360464572906, 'epoch': 1.0, 'step': 808, 'lr': 1.9612577643465342e-05, 'week': 4, 'validation_loss': 0.2404813739484635, 'macro_f1': 0.5363851427205978, 'micro_f1': 0.7414266117969823, 'mae': 0.3559822448271077}\n{'loss': 0.22113360464572906, 'epoch': 1.0, 'step': 808, 'lr': 1.9612577643465342e-05, 'week': 5, 'validation_loss': 0.2404813739484635, 'macro_f1': 0.4609416332849059, 'micro_f1': 0.7113625971650663, 'mae': 0.39457009184588265}\n{'loss': 0.22113360464572906, 'epoch': 1.0, 'step': 808, 'lr': 1.9612577643465342e-05, 'week': 6, 'validation_loss': 0.2404813739484635, 'macro_f1': 0.4213104375668891, 'micro_f1': 0.6846136259716507, 'mae': 0.4315139903085911}\nValidation loss decreased (0.448619 --> 0.240481).  Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 2/10:   0%|          | 0/808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"256ce9d211c64406b4fb8dce410b3a1b"}},"metadata":{}},{"name":"stdout","text":"{'loss': 0.2731664180755615, 'epoch': 1.5, 'step': 1212, 'lr': 3.6421782399043904e-05, 'week': 1, 'validation_loss': 0.22699449340934338, 'macro_f1': 0.77638545631276, 'micro_f1': 0.8808870598994056, 'mae': 0.19244900119721473}\n{'loss': 0.2731664180755615, 'epoch': 1.5, 'step': 1212, 'lr': 3.6421782399043904e-05, 'week': 2, 'validation_loss': 0.22699449340934338, 'macro_f1': 0.7026219631567039, 'micro_f1': 0.8288751714677639, 'mae': 0.24268919530351601}\n{'loss': 0.2731664180755615, 'epoch': 1.5, 'step': 1212, 'lr': 3.6421782399043904e-05, 'week': 3, 'validation_loss': 0.22699449340934338, 'macro_f1': 0.6388195879195356, 'micro_f1': 0.7856652949245542, 'mae': 0.29220762869014605}\n{'loss': 0.2731664180755615, 'epoch': 1.5, 'step': 1212, 'lr': 3.6421782399043904e-05, 'week': 4, 'validation_loss': 0.22699449340934338, 'macro_f1': 0.553751261298326, 'micro_f1': 0.7457704618198445, 'mae': 0.3408102498155725}\n{'loss': 0.2731664180755615, 'epoch': 1.5, 'step': 1212, 'lr': 3.6421782399043904e-05, 'week': 5, 'validation_loss': 0.22699449340934338, 'macro_f1': 0.5151718334405949, 'micro_f1': 0.7133058984910837, 'mae': 0.38770245721895585}\n{'loss': 0.2731664180755615, 'epoch': 1.5, 'step': 1212, 'lr': 3.6421782399043904e-05, 'week': 6, 'validation_loss': 0.22699449340934338, 'macro_f1': 0.4750664359487731, 'micro_f1': 0.6833561957018747, 'mae': 0.42810965240666293}\nValidation loss decreased (0.240481 --> 0.226994).  Saving model ...\n{'loss': 0.30737268924713135, 'epoch': 2.0, 'step': 1616, 'lr': 5.322514587043574e-05, 'week': 1, 'validation_loss': 0.2250309567088666, 'macro_f1': 0.7990442529141473, 'micro_f1': 0.8880887059899406, 'mae': 0.16881281436045162}\n{'loss': 0.30737268924713135, 'epoch': 2.0, 'step': 1616, 'lr': 5.322514587043574e-05, 'week': 2, 'validation_loss': 0.2250309567088666, 'macro_f1': 0.7142053054314825, 'micro_f1': 0.8308184727937814, 'mae': 0.23632385874212666}\n{'loss': 0.30737268924713135, 'epoch': 2.0, 'step': 1616, 'lr': 5.322514587043574e-05, 'week': 3, 'validation_loss': 0.2250309567088666, 'macro_f1': 0.655025750097642, 'micro_f1': 0.7880658436213992, 'mae': 0.2849225835138463}\n{'loss': 0.30737268924713135, 'epoch': 2.0, 'step': 1616, 'lr': 5.322514587043574e-05, 'week': 4, 'validation_loss': 0.2250309567088666, 'macro_f1': 0.5746439426638956, 'micro_f1': 0.7477137631458619, 'mae': 0.33770726317953015}\n{'loss': 0.30737268924713135, 'epoch': 2.0, 'step': 1616, 'lr': 5.322514587043574e-05, 'week': 5, 'validation_loss': 0.2250309567088666, 'macro_f1': 0.5388359305773449, 'micro_f1': 0.7146776406035665, 'mae': 0.385465269336054}\n{'loss': 0.30737268924713135, 'epoch': 2.0, 'step': 1616, 'lr': 5.322514587043574e-05, 'week': 6, 'validation_loss': 0.2250309567088666, 'macro_f1': 0.4642744991850604, 'micro_f1': 0.6800411522633745, 'mae': 0.4256674489118966}\nValidation loss decreased (0.226994 --> 0.225031).  Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 3/10:   0%|          | 0/808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dfcbd2df84f42648574f0adcdf8a463"}},"metadata":{}},{"name":"stdout","text":"{'loss': 0.19237568974494934, 'epoch': 2.5, 'step': 2020, 'lr': 6.551658857891442e-05, 'week': 1, 'validation_loss': 0.2219208037291748, 'macro_f1': 0.8089189026931903, 'micro_f1': 0.8898033836305441, 'mae': 0.16174335689889904}\n{'loss': 0.19237568974494934, 'epoch': 2.5, 'step': 2020, 'lr': 6.551658857891442e-05, 'week': 2, 'validation_loss': 0.2219208037291748, 'macro_f1': 0.7199655442658757, 'micro_f1': 0.8299039780521262, 'mae': 0.2333761513598042}\n{'loss': 0.19237568974494934, 'epoch': 2.5, 'step': 2020, 'lr': 6.551658857891442e-05, 'week': 3, 'validation_loss': 0.2219208037291748, 'macro_f1': 0.6439969558965202, 'micro_f1': 0.7873799725651578, 'mae': 0.28639081295401186}\n{'loss': 0.19237568974494934, 'epoch': 2.5, 'step': 2020, 'lr': 6.551658857891442e-05, 'week': 4, 'validation_loss': 0.2219208037291748, 'macro_f1': 0.5896456957594451, 'micro_f1': 0.7474851394604481, 'mae': 0.33735394086198106}\n{'loss': 0.19237568974494934, 'epoch': 2.5, 'step': 2020, 'lr': 6.551658857891442e-05, 'week': 5, 'validation_loss': 0.2219208037291748, 'macro_f1': 0.5389558175081629, 'micro_f1': 0.7145633287608596, 'mae': 0.3845270474220235}\n{'loss': 0.19237568974494934, 'epoch': 2.5, 'step': 2020, 'lr': 6.551658857891442e-05, 'week': 6, 'validation_loss': 0.2219208037291748, 'macro_f1': 0.4960372560925646, 'micro_f1': 0.678326474622771, 'mae': 0.4266046973958615}\nValidation loss decreased (0.225031 --> 0.221921).  Saving model ...\n{'loss': 0.21580488979816437, 'epoch': 3.0, 'step': 2424, 'lr': 6.99999946009513e-05, 'week': 1, 'validation_loss': 0.21585706059915433, 'macro_f1': 0.8211295518136601, 'micro_f1': 0.8928898033836306, 'mae': 0.15341046776856473}\n{'loss': 0.21580488979816437, 'epoch': 3.0, 'step': 2424, 'lr': 6.99999946009513e-05, 'week': 2, 'validation_loss': 0.21585706059915433, 'macro_f1': 0.7280405949890071, 'micro_f1': 0.8351623228166438, 'mae': 0.21585089471394212}\n{'loss': 0.21580488979816437, 'epoch': 3.0, 'step': 2424, 'lr': 6.99999946009513e-05, 'week': 3, 'validation_loss': 0.21585706059915433, 'macro_f1': 0.6532662927808448, 'micro_f1': 0.7921810699588476, 'mae': 0.26857291079407963}\n{'loss': 0.21580488979816437, 'epoch': 3.0, 'step': 2424, 'lr': 6.99999946009513e-05, 'week': 4, 'validation_loss': 0.21585706059915433, 'macro_f1': 0.5972478830356821, 'micro_f1': 0.7529721079103795, 'mae': 0.3220566683240666}\n{'loss': 0.21580488979816437, 'epoch': 3.0, 'step': 2424, 'lr': 6.99999946009513e-05, 'week': 5, 'validation_loss': 0.21585706059915433, 'macro_f1': 0.5493648402018957, 'micro_f1': 0.7234796524919981, 'mae': 0.3736863024066459}\n{'loss': 0.21580488979816437, 'epoch': 3.0, 'step': 2424, 'lr': 6.99999946009513e-05, 'week': 6, 'validation_loss': 0.21585706059915433, 'macro_f1': 0.5059826617309775, 'micro_f1': 0.6898719707361682, 'mae': 0.4190844371114559}\nValidation loss decreased (0.221921 --> 0.215857).  Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 4/10:   0%|          | 0/808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"593f649d6e7f426a8a819b400576b2b0"}},"metadata":{}},{"name":"stdout","text":"{'loss': 0.26736271381378174, 'epoch': 3.5, 'step': 2828, 'lr': 6.911814926126814e-05, 'week': 1, 'validation_loss': 0.2158154797186886, 'macro_f1': 0.8144208108855588, 'micro_f1': 0.8952903520804756, 'mae': 0.1488907805179265}\n{'loss': 0.26736271381378174, 'epoch': 3.5, 'step': 2828, 'lr': 6.911814926126814e-05, 'week': 2, 'validation_loss': 0.2158154797186886, 'macro_f1': 0.7213152111128484, 'micro_f1': 0.8350480109739369, 'mae': 0.21197242061322139}\n{'loss': 0.26736271381378174, 'epoch': 3.5, 'step': 2828, 'lr': 6.911814926126814e-05, 'week': 3, 'validation_loss': 0.2158154797186886, 'macro_f1': 0.6718463248146612, 'micro_f1': 0.7940100594421583, 'mae': 0.26948557973271436}\n{'loss': 0.26736271381378174, 'epoch': 3.5, 'step': 2828, 'lr': 6.911814926126814e-05, 'week': 4, 'validation_loss': 0.2158154797186886, 'macro_f1': 0.6010967937654915, 'micro_f1': 0.7546867855509831, 'mae': 0.3178662308187447}\n{'loss': 0.26736271381378174, 'epoch': 3.5, 'step': 2828, 'lr': 6.911814926126814e-05, 'week': 5, 'validation_loss': 0.2158154797186886, 'macro_f1': 0.5450698586748596, 'micro_f1': 0.7269090077732052, 'mae': 0.3624092424830727}\n{'loss': 0.26736271381378174, 'epoch': 3.5, 'step': 2828, 'lr': 6.911814926126814e-05, 'week': 6, 'validation_loss': 0.2158154797186886, 'macro_f1': 0.506955129604491, 'micro_f1': 0.6973022405121171, 'mae': 0.40293361339594497}\nValidation loss decreased (0.215857 --> 0.215815).  Saving model ...\n{'loss': 0.216173455119133, 'epoch': 4.0, 'step': 3232, 'lr': 6.652548447282524e-05, 'week': 1, 'validation_loss': 0.2146329001887985, 'macro_f1': 0.8187271625908717, 'micro_f1': 0.8994055784179241, 'mae': 0.1440697400127226}\n{'loss': 0.216173455119133, 'epoch': 4.0, 'step': 3232, 'lr': 6.652548447282524e-05, 'week': 2, 'validation_loss': 0.2146329001887985, 'macro_f1': 0.7241344291143602, 'micro_f1': 0.8382487425697303, 'mae': 0.21326933627928782}\n{'loss': 0.216173455119133, 'epoch': 4.0, 'step': 3232, 'lr': 6.652548447282524e-05, 'week': 3, 'validation_loss': 0.2146329001887985, 'macro_f1': 0.6736369770189338, 'micro_f1': 0.7943529949702788, 'mae': 0.2655946252561483}\n{'loss': 0.216173455119133, 'epoch': 4.0, 'step': 3232, 'lr': 6.652548447282524e-05, 'week': 4, 'validation_loss': 0.2146329001887985, 'macro_f1': 0.5981532628520548, 'micro_f1': 0.7554869684499314, 'mae': 0.31859753661037327}\n{'loss': 0.216173455119133, 'epoch': 4.0, 'step': 3232, 'lr': 6.652548447282524e-05, 'week': 5, 'validation_loss': 0.2146329001887985, 'macro_f1': 0.5602165794064605, 'micro_f1': 0.7263374485596708, 'mae': 0.3645489718742202}\n{'loss': 0.216173455119133, 'epoch': 4.0, 'step': 3232, 'lr': 6.652548447282524e-05, 'week': 6, 'validation_loss': 0.2146329001887985, 'macro_f1': 0.5127864085347602, 'micro_f1': 0.6960448102423411, 'mae': 0.4058833617851036}\nValidation loss decreased (0.215815 --> 0.214633).  Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 5/10:   0%|          | 0/808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5475cf7f07ad4fbeb0a465af18ad3f62"}},"metadata":{}},{"name":"stdout","text":"{'loss': 0.3108179569244385, 'epoch': 4.5, 'step': 3636, 'lr': 6.235200727414045e-05, 'week': 1, 'validation_loss': 0.21387542508866475, 'macro_f1': 0.8044755096351435, 'micro_f1': 0.8943758573388203, 'mae': 0.1442857677234607}\n{'loss': 0.3108179569244385, 'epoch': 4.5, 'step': 3636, 'lr': 6.235200727414045e-05, 'week': 2, 'validation_loss': 0.21387542508866475, 'macro_f1': 0.7046587542270714, 'micro_f1': 0.837219935985368, 'mae': 0.21151231043753138}\n{'loss': 0.3108179569244385, 'epoch': 4.5, 'step': 3636, 'lr': 6.235200727414045e-05, 'week': 3, 'validation_loss': 0.21387542508866475, 'macro_f1': 0.6408307488973576, 'micro_f1': 0.7946959304983996, 'mae': 0.26300141816692824}\n{'loss': 0.3108179569244385, 'epoch': 4.5, 'step': 3636, 'lr': 6.235200727414045e-05, 'week': 4, 'validation_loss': 0.21387542508866475, 'macro_f1': 0.5612175119258054, 'micro_f1': 0.7540009144947416, 'mae': 0.3132655666840398}\n{'loss': 0.3108179569244385, 'epoch': 4.5, 'step': 3636, 'lr': 6.235200727414045e-05, 'week': 5, 'validation_loss': 0.21387542508866475, 'macro_f1': 0.5210922316024135, 'micro_f1': 0.7254229538180155, 'mae': 0.3564950378177935}\n{'loss': 0.3108179569244385, 'epoch': 4.5, 'step': 3636, 'lr': 6.235200727414045e-05, 'week': 6, 'validation_loss': 0.21387542508866475, 'macro_f1': 0.4907552628119249, 'micro_f1': 0.6945587562871514, 'mae': 0.4027668469459856}\nValidation loss decreased (0.214633 --> 0.213875).  Saving model ...\n{'loss': 0.1826334148645401, 'epoch': 5.0, 'step': 4040, 'lr': 5.680699323887897e-05, 'week': 1, 'validation_loss': 0.21142817213051562, 'macro_f1': 0.8224267672351395, 'micro_f1': 0.8990626428898034, 'mae': 0.14190983514674385}\n{'loss': 0.1826334148645401, 'epoch': 5.0, 'step': 4040, 'lr': 5.680699323887897e-05, 'week': 2, 'validation_loss': 0.21142817213051562, 'macro_f1': 0.7240568108641523, 'micro_f1': 0.8390489254686786, 'mae': 0.20589957161650035}\n{'loss': 0.1826334148645401, 'epoch': 5.0, 'step': 4040, 'lr': 5.680699323887897e-05, 'week': 3, 'validation_loss': 0.21142817213051562, 'macro_f1': 0.6548856730345632, 'micro_f1': 0.7960676726108825, 'mae': 0.26140878530506995}\n{'loss': 0.1826334148645401, 'epoch': 5.0, 'step': 4040, 'lr': 5.680699323887897e-05, 'week': 4, 'validation_loss': 0.21142817213051562, 'macro_f1': 0.5733855444740312, 'micro_f1': 0.7554869684499314, 'mae': 0.31048460854222953}\n{'loss': 0.1826334148645401, 'epoch': 5.0, 'step': 4040, 'lr': 5.680699323887897e-05, 'week': 5, 'validation_loss': 0.21142817213051562, 'macro_f1': 0.5277171248507565, 'micro_f1': 0.7265660722450846, 'mae': 0.3564374797114521}\n{'loss': 0.1826334148645401, 'epoch': 5.0, 'step': 4040, 'lr': 5.680699323887897e-05, 'week': 6, 'validation_loss': 0.21142817213051562, 'macro_f1': 0.48537127613629555, 'micro_f1': 0.6947873799725651, 'mae': 0.3964448545445086}\nValidation loss decreased (0.213875 --> 0.211428).  Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 6/10:   0%|          | 0/808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dab83c91a08e495693551654039143e3"}},"metadata":{}},{"name":"stdout","text":"{'loss': 0.28025686740875244, 'epoch': 5.5, 'step': 4444, 'lr': 5.0168492524730965e-05, 'week': 1, 'validation_loss': 0.2128994116100712, 'macro_f1': 0.8212667737589506, 'micro_f1': 0.8989483310470965, 'mae': 0.15024561280430243}\n{'loss': 0.28025686740875244, 'epoch': 5.5, 'step': 4444, 'lr': 5.0168492524730965e-05, 'week': 2, 'validation_loss': 0.2128994116100712, 'macro_f1': 0.7308048426399498, 'micro_f1': 0.8395061728395061, 'mae': 0.21401527878311932}\n{'loss': 0.28025686740875244, 'epoch': 5.5, 'step': 4444, 'lr': 5.0168492524730965e-05, 'week': 3, 'validation_loss': 0.2128994116100712, 'macro_f1': 0.6721029398744213, 'micro_f1': 0.793095564700503, 'mae': 0.27507044083872423}\n{'loss': 0.28025686740875244, 'epoch': 5.5, 'step': 4444, 'lr': 5.0168492524730965e-05, 'week': 4, 'validation_loss': 0.2128994116100712, 'macro_f1': 0.5994457743425434, 'micro_f1': 0.7559442158207591, 'mae': 0.32355658527388237}\n{'loss': 0.28025686740875244, 'epoch': 5.5, 'step': 4444, 'lr': 5.0168492524730965e-05, 'week': 5, 'validation_loss': 0.2128994116100712, 'macro_f1': 0.5534404869607702, 'micro_f1': 0.7221079103795153, 'mae': 0.37379758957545295}\n{'loss': 0.28025686740875244, 'epoch': 5.5, 'step': 4444, 'lr': 5.0168492524730965e-05, 'week': 6, 'validation_loss': 0.2128994116100712, 'macro_f1': 0.507053801400149, 'micro_f1': 0.6897576588934614, 'mae': 0.40999069567209945}\n{'loss': 0.20882195234298706, 'epoch': 6.0, 'step': 4848, 'lr': 4.276938727746874e-05, 'week': 1, 'validation_loss': 0.2107530509432157, 'macro_f1': 0.810788725034913, 'micro_f1': 0.8974622770919067, 'mae': 0.13754313114060843}\n{'loss': 0.20882195234298706, 'epoch': 6.0, 'step': 4848, 'lr': 4.276938727746874e-05, 'week': 2, 'validation_loss': 0.2107530509432157, 'macro_f1': 0.7199586231553524, 'micro_f1': 0.8393918609967993, 'mae': 0.2025209500617393}\n{'loss': 0.20882195234298706, 'epoch': 6.0, 'step': 4848, 'lr': 4.276938727746874e-05, 'week': 3, 'validation_loss': 0.2107530509432157, 'macro_f1': 0.6632046498366028, 'micro_f1': 0.7980109739368998, 'mae': 0.255930035361838}\n{'loss': 0.20882195234298706, 'epoch': 6.0, 'step': 4848, 'lr': 4.276938727746874e-05, 'week': 4, 'validation_loss': 0.2107530509432157, 'macro_f1': 0.5996611472768772, 'micro_f1': 0.7566300868770005, 'mae': 0.3098853839275776}\n{'loss': 0.20882195234298706, 'epoch': 6.0, 'step': 4848, 'lr': 4.276938727746874e-05, 'week': 5, 'validation_loss': 0.2107530509432157, 'macro_f1': 0.5611971943185118, 'micro_f1': 0.7290809327846364, 'mae': 0.3566464214850806}\n{'loss': 0.20882195234298706, 'epoch': 6.0, 'step': 4848, 'lr': 4.276938727746874e-05, 'week': 6, 'validation_loss': 0.2107530509432157, 'macro_f1': 0.5146882599226852, 'micro_f1': 0.6979881115683585, 'mae': 0.3987598432971338}\nValidation loss decreased (0.211428 --> 0.210753).  Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 7/10:   0%|          | 0/808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e65d69d624fc4e489b2d8c71d2ca7025"}},"metadata":{}},{"name":"stdout","text":"{'loss': 0.20513644814491272, 'epoch': 6.5, 'step': 5252, 'lr': 3.498069953016286e-05, 'week': 1, 'validation_loss': 0.20956422091610188, 'macro_f1': 0.8190441415064189, 'micro_f1': 0.9004343850022862, 'mae': 0.12945519541173503}\n{'loss': 0.20513644814491272, 'epoch': 6.5, 'step': 5252, 'lr': 3.498069953016286e-05, 'week': 2, 'validation_loss': 0.20956422091610188, 'macro_f1': 0.6996881668669407, 'micro_f1': 0.8381344307270233, 'mae': 0.1989972746122896}\n{'loss': 0.20513644814491272, 'epoch': 6.5, 'step': 5252, 'lr': 3.498069953016286e-05, 'week': 3, 'validation_loss': 0.20956422091610188, 'macro_f1': 0.6430632189149277, 'micro_f1': 0.7933241883859167, 'mae': 0.2583616904595625}\n{'loss': 0.20513644814491272, 'epoch': 6.5, 'step': 5252, 'lr': 3.498069953016286e-05, 'week': 4, 'validation_loss': 0.20956422091610188, 'macro_f1': 0.5856816959641672, 'micro_f1': 0.7543438500228624, 'mae': 0.31220341653251055}\n{'loss': 0.20513644814491272, 'epoch': 6.5, 'step': 5252, 'lr': 3.498069953016286e-05, 'week': 5, 'validation_loss': 0.20956422091610188, 'macro_f1': 0.5367971556964521, 'micro_f1': 0.7213077274805672, 'mae': 0.3618140154719032}\n{'loss': 0.20513644814491272, 'epoch': 6.5, 'step': 5252, 'lr': 3.498069953016286e-05, 'week': 6, 'validation_loss': 0.20956422091610188, 'macro_f1': 0.49318739416085416, 'micro_f1': 0.6920438957475995, 'mae': 0.4014883214621224}\nValidation loss decreased (0.210753 --> 0.209564).  Saving model ...\n{'loss': 0.1661258339881897, 'epoch': 7.0, 'step': 5656, 'lr': 2.7192986609190955e-05, 'week': 1, 'validation_loss': 0.2114487345451894, 'macro_f1': 0.8129382743749595, 'micro_f1': 0.901806127114769, 'mae': 0.1330470282976395}\n{'loss': 0.1661258339881897, 'epoch': 7.0, 'step': 5656, 'lr': 2.7192986609190955e-05, 'week': 2, 'validation_loss': 0.2114487345451894, 'macro_f1': 0.7305139458289162, 'micro_f1': 0.8396204846822131, 'mae': 0.20239753480041045}\n{'loss': 0.1661258339881897, 'epoch': 7.0, 'step': 5656, 'lr': 2.7192986609190955e-05, 'week': 3, 'validation_loss': 0.2114487345451894, 'macro_f1': 0.6652984826460465, 'micro_f1': 0.7945816186556927, 'mae': 0.2623575984045207}\n{'loss': 0.1661258339881897, 'epoch': 7.0, 'step': 5656, 'lr': 2.7192986609190955e-05, 'week': 4, 'validation_loss': 0.2114487345451894, 'macro_f1': 0.6001870418861889, 'micro_f1': 0.75480109739369, 'mae': 0.31902833517608886}\n{'loss': 0.1661258339881897, 'epoch': 7.0, 'step': 5656, 'lr': 2.7192986609190955e-05, 'week': 5, 'validation_loss': 0.2114487345451894, 'macro_f1': 0.5613971939896719, 'micro_f1': 0.7257658893461363, 'mae': 0.3698406065933204}\n{'loss': 0.1661258339881897, 'epoch': 7.0, 'step': 5656, 'lr': 2.7192986609190955e-05, 'week': 6, 'validation_loss': 0.2114487345451894, 'macro_f1': 0.513277244188784, 'micro_f1': 0.6910150891632373, 'mae': 0.41256427545519114}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 8/10:   0%|          | 0/808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"674f97e166064c8788f429bd3e91dbeb"}},"metadata":{}},{"name":"stdout","text":"{'loss': 0.18554463982582092, 'epoch': 7.5, 'step': 6060, 'lr': 1.9796756959067725e-05, 'week': 1, 'validation_loss': 0.20946215784204178, 'macro_f1': 0.8169807977900381, 'micro_f1': 0.9010059442158209, 'mae': 0.1362103647665058}\n{'loss': 0.18554463982582092, 'epoch': 7.5, 'step': 6060, 'lr': 1.9796756959067725e-05, 'week': 2, 'validation_loss': 0.20946215784204178, 'macro_f1': 0.717789013907657, 'micro_f1': 0.8399634202103338, 'mae': 0.20308275568683126}\n{'loss': 0.18554463982582092, 'epoch': 7.5, 'step': 6060, 'lr': 1.9796756959067725e-05, 'week': 3, 'validation_loss': 0.20946215784204178, 'macro_f1': 0.6612453727180367, 'micro_f1': 0.7951531778692272, 'mae': 0.2629286394321868}\n{'loss': 0.18554463982582092, 'epoch': 7.5, 'step': 6060, 'lr': 1.9796756959067725e-05, 'week': 4, 'validation_loss': 0.20946215784204178, 'macro_f1': 0.592080645343338, 'micro_f1': 0.7557155921353452, 'mae': 0.3156606420706481}\n{'loss': 0.18554463982582092, 'epoch': 7.5, 'step': 6060, 'lr': 1.9796756959067725e-05, 'week': 5, 'validation_loss': 0.20946215784204178, 'macro_f1': 0.551616526824731, 'micro_f1': 0.7257658893461363, 'mae': 0.3660714971412635}\n{'loss': 0.18554463982582092, 'epoch': 7.5, 'step': 6060, 'lr': 1.9796756959067725e-05, 'week': 6, 'validation_loss': 0.20946215784204178, 'macro_f1': 0.5077396655829812, 'micro_f1': 0.6943301326017376, 'mae': 0.4077990907503662}\nValidation loss decreased (0.209564 --> 0.209462).  Saving model ...\n{'loss': 0.22884151339530945, 'epoch': 8.0, 'step': 6464, 'lr': 1.316288841841575e-05, 'week': 1, 'validation_loss': 0.20900985485185747, 'macro_f1': 0.8158451889405031, 'micro_f1': 0.9005486968449932, 'mae': 0.13334884875722308}\n{'loss': 0.22884151339530945, 'epoch': 8.0, 'step': 6464, 'lr': 1.316288841841575e-05, 'week': 2, 'validation_loss': 0.20900985485185747, 'macro_f1': 0.7126565421975829, 'micro_f1': 0.8399634202103338, 'mae': 0.20090496339346545}\n{'loss': 0.22884151339530945, 'epoch': 8.0, 'step': 6464, 'lr': 1.316288841841575e-05, 'week': 3, 'validation_loss': 0.20900985485185747, 'macro_f1': 0.6540296177306038, 'micro_f1': 0.7958390489254686, 'mae': 0.25881709279484516}\n{'loss': 0.22884151339530945, 'epoch': 8.0, 'step': 6464, 'lr': 1.316288841841575e-05, 'week': 4, 'validation_loss': 0.20900985485185747, 'macro_f1': 0.5816934094643679, 'micro_f1': 0.7544581618655692, 'mae': 0.3130865900084244}\n{'loss': 0.22884151339530945, 'epoch': 8.0, 'step': 6464, 'lr': 1.316288841841575e-05, 'week': 5, 'validation_loss': 0.20900985485185747, 'macro_f1': 0.5297970632911791, 'micro_f1': 0.7226794695930499, 'mae': 0.3599692014199034}\n{'loss': 0.22884151339530945, 'epoch': 8.0, 'step': 6464, 'lr': 1.316288841841575e-05, 'week': 6, 'validation_loss': 0.20900985485185747, 'macro_f1': 0.4738626467543972, 'micro_f1': 0.6904435299497028, 'mae': 0.40173990036537993}\nValidation loss decreased (0.209462 --> 0.209010).  Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 9/10:   0%|          | 0/808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a49f747414ce47c8ac5f98ad342b6c4a"}},"metadata":{}},{"name":"stdout","text":"{'loss': 0.32663875818252563, 'epoch': 8.5, 'step': 6868, 'lr': 7.624030856485954e-06, 'week': 1, 'validation_loss': 0.21021646282811096, 'macro_f1': 0.8204229874010932, 'micro_f1': 0.9006630086877, 'mae': 0.12935614982738539}\n{'loss': 0.32663875818252563, 'epoch': 8.5, 'step': 6868, 'lr': 7.624030856485954e-06, 'week': 2, 'validation_loss': 0.21021646282811096, 'macro_f1': 0.7318817931758174, 'micro_f1': 0.8414494741655236, 'mae': 0.19841274517968155}\n{'loss': 0.32663875818252563, 'epoch': 8.5, 'step': 6868, 'lr': 7.624030856485954e-06, 'week': 3, 'validation_loss': 0.21021646282811096, 'macro_f1': 0.662865479093901, 'micro_f1': 0.7970964791952446, 'mae': 0.25576489300972327}\n{'loss': 0.32663875818252563, 'epoch': 8.5, 'step': 6868, 'lr': 7.624030856485954e-06, 'week': 4, 'validation_loss': 0.21021646282811096, 'macro_f1': 0.5958459766247733, 'micro_f1': 0.7557155921353452, 'mae': 0.3099284546988649}\n{'loss': 0.32663875818252563, 'epoch': 8.5, 'step': 6868, 'lr': 7.624030856485954e-06, 'week': 5, 'validation_loss': 0.21021646282811096, 'macro_f1': 0.545121245967202, 'micro_f1': 0.723708276177412, 'mae': 0.3571387857217137}\n{'loss': 0.32663875818252563, 'epoch': 8.5, 'step': 6868, 'lr': 7.624030856485954e-06, 'week': 6, 'validation_loss': 0.21021646282811096, 'macro_f1': 0.4912218856196808, 'micro_f1': 0.6921582075903063, 'mae': 0.39846668522918666}\n{'loss': 0.2240154892206192, 'epoch': 9.0, 'step': 7272, 'lr': 3.4579257196884897e-06, 'week': 1, 'validation_loss': 0.20930410867583923, 'macro_f1': 0.8206150868560282, 'micro_f1': 0.9011202560585276, 'mae': 0.12892584019179468}\n{'loss': 0.2240154892206192, 'epoch': 9.0, 'step': 7272, 'lr': 3.4579257196884897e-06, 'week': 2, 'validation_loss': 0.20930410867583923, 'macro_f1': 0.7308699816587466, 'micro_f1': 0.8405349794238683, 'mae': 0.19837681551248237}\n{'loss': 0.2240154892206192, 'epoch': 9.0, 'step': 7272, 'lr': 3.4579257196884897e-06, 'week': 3, 'validation_loss': 0.20930410867583923, 'macro_f1': 0.6593627072484995, 'micro_f1': 0.7961819844535893, 'mae': 0.25646952166109166}\n{'loss': 0.2240154892206192, 'epoch': 9.0, 'step': 7272, 'lr': 3.4579257196884897e-06, 'week': 4, 'validation_loss': 0.20930410867583923, 'macro_f1': 0.590292328239408, 'micro_f1': 0.7554869684499314, 'mae': 0.30986889002818274}\n{'loss': 0.2240154892206192, 'epoch': 9.0, 'step': 7272, 'lr': 3.4579257196884897e-06, 'week': 5, 'validation_loss': 0.20930410867583923, 'macro_f1': 0.5446571501251237, 'micro_f1': 0.7247370827617741, 'mae': 0.358499117291606}\n{'loss': 0.2240154892206192, 'epoch': 9.0, 'step': 7272, 'lr': 3.4579257196884897e-06, 'week': 6, 'validation_loss': 0.20930410867583923, 'macro_f1': 0.5045973391160347, 'micro_f1': 0.6929583904892547, 'mae': 0.40166426362537494}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 10/10:   0%|          | 0/808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76e3ee90516f4948b9f2f454f7ddd435"}},"metadata":{}},{"name":"stdout","text":"{'loss': 0.25114649534225464, 'epoch': 9.5, 'step': 7676, 'lr': 8.734789157224429e-07, 'week': 1, 'validation_loss': 0.20984569753425708, 'macro_f1': 0.8213065688840105, 'micro_f1': 0.9012345679012346, 'mae': 0.12875720636671453}\n{'loss': 0.25114649534225464, 'epoch': 9.5, 'step': 7676, 'lr': 8.734789157224429e-07, 'week': 2, 'validation_loss': 0.20984569753425708, 'macro_f1': 0.7300849574764591, 'micro_f1': 0.840992226794696, 'mae': 0.19838674039285054}\n{'loss': 0.25114649534225464, 'epoch': 9.5, 'step': 7676, 'lr': 8.734789157224429e-07, 'week': 3, 'validation_loss': 0.20984569753425708, 'macro_f1': 0.6644687394116163, 'micro_f1': 0.7968678555098309, 'mae': 0.2566883089287659}\n{'loss': 0.25114649534225464, 'epoch': 9.5, 'step': 7676, 'lr': 8.734789157224429e-07, 'week': 4, 'validation_loss': 0.20984569753425708, 'macro_f1': 0.598117608631383, 'micro_f1': 0.7550297210791038, 'mae': 0.31057319012761037}\n{'loss': 0.25114649534225464, 'epoch': 9.5, 'step': 7676, 'lr': 8.734789157224429e-07, 'week': 5, 'validation_loss': 0.20984569753425708, 'macro_f1': 0.5530563037251769, 'micro_f1': 0.7241655235482397, 'mae': 0.35816149073661263}\n{'loss': 0.25114649534225464, 'epoch': 9.5, 'step': 7676, 'lr': 8.734789157224429e-07, 'week': 6, 'validation_loss': 0.20984569753425708, 'macro_f1': 0.5038841218024265, 'micro_f1': 0.691358024691358, 'mae': 0.4004751001413437}\n{'loss': 0.24246972799301147, 'epoch': 10.0, 'step': 8080, 'lr': 2.853990486928992e-10, 'week': 1, 'validation_loss': 0.20887975157171057, 'macro_f1': 0.8179696996448111, 'micro_f1': 0.9016918152720622, 'mae': 0.1288738743973408}\n{'loss': 0.24246972799301147, 'epoch': 10.0, 'step': 8080, 'lr': 2.853990486928992e-10, 'week': 2, 'validation_loss': 0.20887975157171057, 'macro_f1': 0.7321002675533438, 'micro_f1': 0.8417924096936443, 'mae': 0.1982857630633247}\n{'loss': 0.24246972799301147, 'epoch': 10.0, 'step': 8080, 'lr': 2.853990486928992e-10, 'week': 3, 'validation_loss': 0.20887975157171057, 'macro_f1': 0.6594129653462422, 'micro_f1': 0.7962962962962963, 'mae': 0.2566432317143676}\n{'loss': 0.24246972799301147, 'epoch': 10.0, 'step': 8080, 'lr': 2.853990486928992e-10, 'week': 4, 'validation_loss': 0.20887975157171057, 'macro_f1': 0.5904096348672961, 'micro_f1': 0.7556012802926383, 'mae': 0.3104441279749258}\n{'loss': 0.24246972799301147, 'epoch': 10.0, 'step': 8080, 'lr': 2.853990486928992e-10, 'week': 5, 'validation_loss': 0.20887975157171057, 'macro_f1': 0.5511267276355462, 'micro_f1': 0.7254229538180155, 'mae': 0.35843495684157217}\n{'loss': 0.24246972799301147, 'epoch': 10.0, 'step': 8080, 'lr': 2.853990486928992e-10, 'week': 6, 'validation_loss': 0.20887975157171057, 'macro_f1': 0.5003841183995383, 'micro_f1': 0.6914723365340649, 'mae': 0.4009315140056634}\nValidation loss decreased (0.209010 --> 0.208880).  Saving model ...\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def predict(x, static=None):\n    if static is None:\n        out, _ = model(torch.tensor(x), val_h)\n    else:\n        out, _ = model(torch.tensor(x), val_h, static)\n    return out\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:32:38.925664Z","iopub.execute_input":"2024-11-11T03:32:38.926024Z","iopub.status.idle":"2024-11-11T03:32:38.931354Z","shell.execute_reply.started":"2024-11-11T03:32:38.925990Z","shell.execute_reply":"2024-11-11T03:32:38.930560Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"dict_map = {\n    \"y_pred\": [],\n    \"y_pred_rounded\": [],\n    \"fips\": [],\n    \"date\": [],\n    \"y_true\": [],\n    \"week\": [],\n}\ni = 0\nfor x, static, y in tqdm(\n    valid_loader,\n    desc=\"validation predictions...\",\n):\n    val_h = tuple([each.data.to(device) for each in model.init_hidden(len(x))])\n    with torch.no_grad():\n        if use_static:\n            pred = predict(x, static).clone().detach()\n        else:\n            pred = predict(x).clone().detach()\n    for w in range(output_weeks):\n        dict_map[\"y_pred\"] += [float(p[w]) for p in pred]\n        dict_map[\"y_pred_rounded\"] += [int(p.round()[w]) for p in pred]\n        dict_map[\"fips\"] += [f[1][0] for f in valid_fips[i : i + len(x)]]\n        dict_map[\"date\"] += [f[1][1] for f in valid_fips[i : i + len(x)]]\n        dict_map[\"y_true\"] += [float(item[w]) for item in y]\n        dict_map[\"week\"] += [w] * len(x)\n    i += len(x)\ndf = pd.DataFrame(dict_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:35:54.109179Z","iopub.execute_input":"2024-11-11T03:35:54.109510Z","iopub.status.idle":"2024-11-11T03:36:00.233518Z","shell.execute_reply.started":"2024-11-11T03:35:54.109481Z","shell.execute_reply":"2024-11-11T03:36:00.232707Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"validation predictions...:   0%|          | 0/69 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"940aa3b3b790474e9fcb1287d07660b8"}},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"for w in range(6):\n    wdf = df[df['week']==w]\n    mae = mean_absolute_error(wdf['y_true'], wdf['y_pred']).round(3)\n    f1 = f1_score(wdf['y_true'].round(),wdf['y_pred'].round(), average='macro').round(3)\n    print(f\"Week {w+1}\", f\"MAE {mae}\", f\"F1 {f1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:36:02.821952Z","iopub.execute_input":"2024-11-11T03:36:02.822274Z","iopub.status.idle":"2024-11-11T03:36:02.873287Z","shell.execute_reply.started":"2024-11-11T03:36:02.822246Z","shell.execute_reply":"2024-11-11T03:36:02.872372Z"}},"outputs":[{"name":"stdout","text":"Week 1 MAE 0.133 F1 0.824\nWeek 2 MAE 0.201 F1 0.716\nWeek 3 MAE 0.259 F1 0.645\nWeek 4 MAE 0.312 F1 0.592\nWeek 5 MAE 0.36 F1 0.541\nWeek 6 MAE 0.402 F1 0.483\n","output_type":"stream"}],"execution_count":33}]}